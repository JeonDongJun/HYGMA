# --- HGCN-QMIX specific parameters ---

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 100000

# 优化器
optim_beta1: 0.9  # AdamW 的一阶动量系数
optim_beta2: 0.999  # AdamW 的二阶动量系数
optim_eps: 1e-8  # 数值稳定性的小量
weight_decay: 0.01  # 权重衰减

#runner: "parallel"
batch_size_run: 1 # Number of environments to run in parallel
runner: "episode"# Runs 1 env for an episode

# 그룹/개인 성향을 통한 행동 편향 설정 (실험별로 공격/방어 스타일을 다르게 부여 가능)
behavior_bias:
  enabled: False
  attack_start_action: 6   # SMAC 기본 공격 액션 시작 index
  hold_actions: [0, 5]     # 대기/정지로 간주할 액션 index 목록
  # 개별 성향 이름에 따른 편향 값. 필요 시 자유롭게 추가/수정.
  profiles:
    aggressive:
      attack_bias: 1.0
      move_bias: -0.2
      hold_bias: -0.1
    defensive:
      attack_bias: -0.5
      move_bias: 0.2
      hold_bias: 0.6
  # 에이전트별 적용할 성향 이름(길이 n_agents). 예: ["aggressive", "aggressive", "defensive", ...]
  agent_personalities: []

mac: "hygma_mac"

batch_size: 128 # Number of episodes to train on
buffer_size: 5000 # Size of the replay buffer

# update the target network every {} episodes
target_update_interval: 200

# use the Q_Learner to train
agent_output_type: "q"
learner: "hgcn_learner"
double_q: True
mixer: "qmix"
mixing_embed_dim: 32
hypernet_layers: 2
hypernet_embed: 64

# 聚类相关配置
clustering_interval: 100000  # 时间步检查一次聚类
state_history_length: 5000  # 用于聚类的状态历史长度
behavior_history_length: 5000  # 用于聚类的行为历史长度
stability_threshold: 0.6  # 如果少于40%的智能体需要移动，则保持原有分组
min_clusters: 2
max_clusters: 3

# 固定分组
fix_grouping_steps: 2
fix_hgcn_steps: 2

# HGCN相关配置
#hgcn_in_dim: 96
#hidden_dim_scale: 1.0
hgcn_out_dim: 48
hgcn_hidden_dim: 64
hgcn_num_layers: 2

#init_agent_groups: [[0, 1, 2, 3, 4]]

# loss 超参数
lambda_consistency: 0.001
lambda_attention: 0.01

name: "hygma"


